# Gemini 2.5 Flash Standardization - Complete ‚úÖ

**Date:** December 5, 2025  
**Purpose:** Standardize all AI tools to use `gemini-2.5-flash` for reliability and consistency

---

## üéØ What Changed

All AI endpoints now use **`gemini-2.5-flash`** as the primary model with automatic fallbacks to ensure reliability.

### Updated Endpoints

1. **‚úÖ Chatbot** (`/api/chat/respond`)
   - Model: `gemini-2.5-flash`
   - Purpose: Fast, low-latency conversational responses

2. **‚úÖ Blog Writer** (`/api/blog/generate`)
   - Model: `gemini-2.5-flash` (changed from gemini-2.5-pro)
   - Uses `generateJSON()` with retry/fallback logic
   - Purpose: SEO-optimized blog post generation

3. **‚úÖ Page Builder AI** (`/api/ai/block-suggestions`)
   - Model: `gemini-2.5-flash` (changed from gemini-2.5-pro)
   - Purpose: Visual block suggestions for page builder

4. **‚úÖ Lead Scoring** (`/api/leads/score`)
   - Model: `gemini-2.5-flash`
   - Purpose: AI-powered lead qualification (0-100 score)

5. **‚úÖ SEO Tools** (`/api/ai/content-suggestions`)
   - Model: `gemini-2.5-flash`
   - Purpose: Meta descriptions, titles, keyword analysis

6. **‚úÖ Gallery Alt Text** (`/api/gallery/generate-alt-text`)
   - Model: `gemini-2.5-flash`
   - Purpose: Accessible, SEO-friendly image descriptions

7. **‚úÖ Gallery Analysis** (`/api/gallery/analyze`)
   - Model: `gemini-2.5-flash`
   - Purpose: Batch image categorization and tagging

---

## üîß Technical Improvements

### 1. Blog Post Generation Refactor
**File:** `lib/ai-client.ts` - `generateBlogPost()`

**Before:**
```typescript
// Direct model.generateContent() call - no retry/fallback
const model = createAIClient({ model: "gemini-2.5-pro", ... });
const result = await model.generateContent(prompt);
```

**After:**
```typescript
// Uses generateJSON() with built-in retry/fallback logic
const blogPost = await generateJSON<BlogPost>(prompt, {
  model: "gemini-2.5-flash",
  retries: 3,
  retryDelayMs: 2000,
});
```

**Benefits:**
- ‚úÖ Automatic retry on failure (3 attempts)
- ‚úÖ Exponential backoff (2s delay)
- ‚úÖ Model fallback if flash unavailable
- ‚úÖ Better error handling and logging

### 2. JSON Response Format Handling
**File:** `lib/ai-client.ts` - `generateText()`

Added fallback for JSON mode response extraction:

```typescript
try {
  text = result.response.text().trim();
} catch (textError) {
  // Fallback for JSON mode responses
  const candidates = result.response.candidates;
  if (candidates && candidates[0]?.content?.parts?.[0]?.text) {
    text = candidates[0].content.parts[0].text.trim();
  }
}
```

**Fixes:** Handles different response structures when using `responseMimeType: "application/json"`

### 3. Chatbot Zod Schema Fix
**File:** `app/api/chat/respond/route.ts`

**Before:**
```typescript
imageData: z.string().optional() // Rejected null values
```

**After:**
```typescript
imageData: z.string().nullish() // Accepts null, undefined, or string
```

**Fixes:** Chatbot 400 error when no image attached

---

## üöÄ Model Fallback Strategy

**Primary Model:** `gemini-2.5-flash`

**Fallback Chain:**
1. `gemini-2.5-flash` ‚Üê **PRIMARY**
2. `gemini-2.5-pro`
3. `gemini-2.5-flash-lite`
4. `gemini-1.5-flash-latest`
5. `gemini-1.5-flash`
6. `gemini-1.5-pro-latest`
7. `gemini-1.5-pro`

**Defined in:** `lib/ai-client.ts` ‚Üí `MODEL_FALLBACKS`

---

## üìä Why Gemini 2.5 Flash?

| Feature | Benefit |
|---------|---------|
| **Speed** | 2x faster than Pro models |
| **Cost** | Lower API costs for high-volume use |
| **Availability** | More stable, fewer quota issues |
| **Quality** | Sufficient for all current use cases |
| **Multimodal** | Supports text + images (chatbot vision) |

**When to use Pro:** Only if Flash quality isn't sufficient (currently not needed)

---

## üîê Environment Variables

**Netlify Production:**
```bash
GOOGLE_GENAI_MODEL=gemini-2.5-flash  # Optional override
GOOGLE_API_KEY=<your-key>             # Required
```

**Local Development (.env.local):**
```bash
GOOGLE_GENAI_MODEL=gemini-2.5-flash  # Optional override
GOOGLE_API_KEY=<your-key>             # Required
```

**Note:** If `GOOGLE_GENAI_MODEL` is not set, defaults to `gemini-2.5-flash` automatically.

---

## ‚úÖ Testing Checklist

- [x] Chatbot responds with AI-generated messages
- [x] Blog writer generates full posts without 502 errors
- [x] Page builder AI suggests relevant blocks
- [x] Lead scoring returns 0-100 scores
- [x] SEO tools generate meta descriptions
- [x] Gallery alt text generates for images
- [x] All endpoints have retry/fallback logic

---

## üìù Files Modified

1. `lib/ai-client.ts` - Core AI client
   - Updated `generateBlogPost()` to use `generateJSON()`
   - Added JSON response format fallback in `generateText()`
   - Changed model from gemini-2.5-pro to gemini-2.5-flash

2. `app/api/blog/generate/route.ts` - Blog generation endpoint
   - Updated logging to reflect gemini-2.5-flash

3. `app/api/ai/block-suggestions/route.ts` - Page builder AI
   - Changed model from gemini-2.5-pro to gemini-2.5-flash

4. `app/api/chat/respond/route.ts` - Chatbot endpoint
   - Fixed Zod schema: `imageData: z.string().nullish()`

---

## üéâ Results

**Before:**
- ‚ùå Blog writer returned 502 "Empty response" errors
- ‚ùå Chatbot returned 400 validation errors
- ‚ö†Ô∏è Inconsistent model usage (pro vs flash)
- ‚ö†Ô∏è No retry logic on blog generation

**After:**
- ‚úÖ Blog writer has robust retry/fallback logic
- ‚úÖ Chatbot works with or without images
- ‚úÖ All tools use consistent gemini-2.5-flash
- ‚úÖ Better error handling and logging across all endpoints
- ‚úÖ Faster response times (flash is 2x faster)

---

## üîÑ Rollback Instructions

If you need to revert to gemini-2.5-pro for specific tools:

1. Edit the endpoint file (e.g., `app/api/blog/generate/route.ts`)
2. Change `model: "gemini-2.5-flash"` to `model: "gemini-2.5-pro"`
3. Redeploy

**Not recommended** unless quality issues are observed with flash.

---

**Standardization completed:** December 5, 2025  
**Status:** Production Ready ‚úÖ
